---
title: "Yolo Bypass near Lisbon Weir (LIS) Station History  \nEstablished on 3/04/2013"
author: "Amanda Maguire  \nDepartment of Water Resources  \namanda.maguire@water.ca.gov"
date: "Updated: 28 January 2024"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
---

```{r setup, include=FALSE}
#include = FALSE prevents the R code or anything produced (i.e. tables) from being rendered into document.
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(readxl)
library(tidyverse)
library(lubridate)
library(dataRetrieval)
library(scales)
library(dplyr)
library(scales)
library(gt)
library(plotly)
```

``` {r include = FALSE}
wyt <- read_excel(
  path = "WY Type Indices.xlsx",
  sheet = "Sacramento Valley Index",
  col_names = TRUE)

#WY Index dataframe clean -- only need to clean once. Will reuse for each station.
SAC_WYIndex <- wyt %>% filter(WY%in%c(2014:2023)) %>% select(WY,Index,`Yr-type`) #Change years to reflect the years the station has been collecting data
SAC_WYIndex[SAC_WYIndex == "BN"] <- "Normal"
SAC_WYIndex[SAC_WYIndex == "AN"] <- "Normal"
SAC_WYIndex[SAC_WYIndex == "D"] <- "Dry"
SAC_WYIndex[SAC_WYIndex == "C"] <- "Dry"
SAC_WYIndex[SAC_WYIndex == "W"] <- "Wet"
unique(SAC_WYIndex$`Yr-type`)


#Continuous WQ import
df_raw_L <- read_csv(
  file = "LIS_por_raw.csv",  #######*add file name----
  col_names = FALSE,     #add column names later
  skip = 3,              #skip top 3 rows
  col_types = "cdddddddddddd")  # "c" = character, "d" = numeric, "-" = skip

#III. DATA CLEAN & SUMMARIZE---------------------------
#Name the columns for the parameters your station has
names(df_raw_L) <- c(
  "DateTime",
  "Specific Conductance (µS/cm)", "SpCnd_q",
  "Water Temperature (°C)", "WT_q",
  "Turbidity (FNU)", "Turb_q",
  "Dissolved Oxygen (mg/L)", "DO_q",
  "pH units", "pH_q",
  "Chlorophyll Fluorescence (µg/L)", "Chla_q",
  "Depth (m)", "Depth_q",
  "fDOM (QSU)", "fDOM_q")

df_clean_L <- df_raw_L %>% 
  mutate(DateTime = mdy_hm(DateTime)) %>% 
  mutate(DateTime = floor_date(DateTime, "15 minute")) %>%
  complete(DateTime = seq.POSIXt(min(DateTime), max(DateTime), by = "15 min")) %>%
  mutate(Date= as.Date(floor_date(DateTime, "day"))) %>%
  select(c(2,4,6,8,10,12,14,16,18)) %>%     ##update for the number of parameters. Need to add an extra column so with three parameters need columns 2 to 8
  filter(Date < '2024-09-30') %>% #update date
  pivot_longer(cols = c(1:8), names_to = "Parameter", values_to = "Value") %>%
  addWaterYear() %>% 
  rename(WY = waterYear) %>%
  mutate(StationCode = "LIS") %>%     #####*UPDATE station name------
  mutate(CDate=as.Date(paste0("1904","-",month(Date),"-",day(Date))))

#IV. CREATE DATA FRAME WITH CONTINUOUS WATER QUALITY AND WATER YEAR TYPE INDEX----
df_cleanWY_L <- full_join(df_clean_L,SAC_WYIndex) %>% 
  group_by(StationCode, Parameter, `Yr-type`, CDate) %>% 
  summarize(Daily_avg = mean(Value, na.rm=TRUE)) %>% 
  ungroup() %>% 
  #seq along dates starting with the beginning of the water year
  mutate(CDate=as.Date(paste0(ifelse(month(CDate) < 10, "1905", "1904"),
                              "-", month(CDate), "-", day(CDate))))


#V. CONTINUOUS FIGURES--------------------
## WY Type Continuous Trends--------------
WY_plots_L <- df_cleanWY_L %>% split(.$Parameter) %>% 
  map(~ ggplot(., aes(x = CDate, y = Daily_avg, color = `Yr-type`)) + 
        geom_line() +
        theme_bw() +
        scale_colour_manual(values = c("#ED7D31","#A5A5A5","#4472C4")) +
        labs(y = .$Parameter,
             x = "Average Date",
             colour = "WY Type") +
        scale_x_date(labels = date_format("%b"),
                     breaks = breaks_pretty(15)))

#WY_plots_L

##Export-------- 
####*before saving, UPDATE station in filenames---------
#ggsave(WY_plots$`Chlorophyll Fluorescence (µg/L)` , filename = "ORI_chlaPORtrends.tiff", device = "tiff", width = 6.5, height = 3)
#ggsave(WY_plots$`Depth (ft)` , filename = "ORI_depthPORtrends.tiff", device = "tiff", width = 6.5, height = 3)
#ggsave(WY_plots$`Dissolved Oxygen (mg/L)` , filename = "ORI_doPORtrends.tiff", device = "tiff", width = 6.5, height = 3)
#ggsave(WY_plots$`pH units` , filename = "ORI_phPORtrends.tiff", device = "tiff", width = 6.5, height = 3)
#ggsave(WY_plots$`Specific Conductance (µS/cm)` , filename = "ORI_spcndPORtrends.tiff", device = "tiff", width = 6.5, height = 3)
#ggsave(WY_plots$`Turbidity (FNU)` , filename = "ORI_turbPORtrends.tiff", device = "tiff", width = 6.5, height = 3)
#ggsave(WY_plots$`Water Temperature (°C)` , filename = "ORI_wtPORtrends.tiff", device = "tiff", width = 6.5, height = 3)

## POR Histograms------------------------
histo_plot <- df_cleanWY_L %>% ggplot(., aes(x = Daily_avg)) + 
  facet_wrap(~Parameter, scales = 'free_x') +
  geom_histogram(binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3))) +
  theme_bw() +
  labs(x = "Daily Average")

#histo_plot

####*before saving, UPDATE station in filename---------
#ggsave(histo_plot, filename = "ORI_histogram.tiff", device = "tiff", width = 6.5, height = 8.5)

#VI. CONTINUOUS SUMMARY TABLES------------
#Create the dataframe
df_cleanSUM <- full_join(df_clean_L,SAC_WYIndex) %>% 
  group_by(StationCode, Parameter, Date) %>% 
  summarize(Daily_avg = mean(Value, na.rm=TRUE)) %>% 
  ungroup()

#Calculate the summary table
df_sum_table <- df_cleanSUM %>% group_by(StationCode, Parameter) %>% 
  summarize(min = min(Daily_avg, na.rm = TRUE),
            max = max(Daily_avg, na.rm = TRUE),
            count = n(),                                          #check that count is correct
            mean = mean(Daily_avg, na.rm=TRUE),
            #median = median(Daily_avg, na.rm = TRUE),
            sd = sd(Daily_avg, na.rm=TRUE)) 

#Find max and min value occurrence dates
df_max <- df_cleanSUM %>% group_by(StationCode, Parameter) %>% slice_max(Daily_avg) %>% select(StationCode, Parameter, Date) %>% rename("max_date" = Date)
df_min <- df_cleanSUM %>% group_by(StationCode, Parameter) %>% slice_min(Daily_avg) %>% select(StationCode, Parameter, Date) %>% rename("min_date" = Date)

#Join tables
POR_sum_table <- full_join(full_join(df_sum_table,df_max), df_min) %>% 
  select(StationCode,
         Parameter,
         min,
         min_date,
         max,
         max_date,
         count,
         mean,
         #median,
         sd)
```

```{r include=FALSE}
df_raw_dis <- read_csv(
  file = "LIS_por_discrete.csv",  #######*add file name----
  col_names = TRUE) 

#III. DATA CLEAN ---------------------------
#remove rows of metadata at bottom of df
df_dis <- head(df_raw_dis, -2)  #######*check data trim----   

df_clean_dis <- df_dis %>% 
  rename(DateTime = `CollectionDate`,
         StationCode = 'ShortStationName') %>%
  mutate(DateTime = mdy_hm(DateTime)) %>% 
  mutate(Date= as.Date(floor_date(DateTime, "day"))) %>% 
  mutate(Year = year(DateTime)) %>%
  #separate <RL data into new RL and value columns.
  mutate(RL = case_when(grepl("<", Result) ~ "<",
                        TRUE ~ "=")) %>% 
  mutate(value = case_when(grepl("<", Result) ~ `RptLimit`,
                           TRUE ~ as.numeric(Result))) %>% 
  relocate(c(RL,value), .before = Result) %>%
  #keep data through 2024
  filter(!Year==2025) %>%
  #remove duplicate samples
  filter(is.na(Notes)|Notes!="Duplicate") %>% distinct()
  
#IV. DISCRETE SUMMARY TABLES------------
##1. Calculate the summary table---------
df_dis_sum_table <- df_clean_dis %>% 
  group_by(StationCode,Analyte) %>% 
  summarize(total_count = n(),   
            mean = mean(value, na.rm = TRUE),
            sd = sd(value, na.rm=TRUE)) 

##2. Find MAXIMUM Results and occurrence date(s)---------
df_dis_max <- df_clean_dis %>% 
  group_by(StationCode,Analyte) %>% 
  slice_max(value) %>% 
  select(Analyte,Result,Date,Year) %>% 
  rename("max_Result" = Result, "max_date" = Date)  

#check results
df_dis_max 
#there are multiple days that a maximum sample value occurred (see VSS, rows 8-10). 
#summarize data for first and last date of occurrence and number of occurences
max_data <- df_dis_max %>% group_by(StationCode,Analyte,max_Result) %>% summarize(first_max = min(max_date),
                                                                       last_max = max(max_date),
                                                                       n_max= n())

##3. Find MINIMUM Results and occurrence date(s)-----------
df_dis_min <- df_clean_dis %>% 
  group_by(StationCode,Analyte) %>% 
  slice_min(value) %>% 
  select(Analyte,Result,Date,Year) %>% 
  rename("min_Result" = Result, "min_date" = Date) 

#check results
df_dis_min %>% print(n=30)
#If needed Remove the higher values (1) from the results.
df_dis_min <- df_dis_min %>% filter(!min_Result=="0.01") %>% print(n=24)
df_dis_min <- df_dis_min %>% filter(!min_Result=="0.5") %>% print(n=24)
df_dis_min <- df_dis_min %>% filter(!min_Result=="N.S.") %>% print(n=24)
#there are multiple days that a minimum sample value occurred (see chla, pheoa, TSS, and VSS). 
#summarize data for first and last date of occurrence and number of occurences
min_data <- df_dis_min %>% group_by(StationCode,Analyte,min_Result) %>% summarize(first_min = min(min_date),
                                                                       last_min = max(min_date),
                                                                       n_min= n())

##4. Join all three summary tables---------
dis_sum_table_all <- full_join(full_join(min_data,max_data), df_dis_sum_table)
```

# Station Rationale

Department of Water Resources (DWR) North Central Region Office (NCRO) Water Quality Evaluation Section (WQES) maintains monitoring equipment for continuous water quality using a Yellow Springs Instruments (YSI) multiparameter sonde and collects discrete water samples at this site for the Yolo Bypass Monitoring Program to support the Yolo Bypass Fish and Invertebrate Monitoring Program and the North Delta Food Subsidies (NDFS) study. Yolo Bypass near Lisbon Weir (LIS) is part of the monitoring network for NDFS, an adaptive management project that monitors the effects of the North Delta Flow Action (NDFA). The NDFA is a joint effort between DWR, Glenn-Colusa Irrigation District, Reclamation Districts 108 and 2035, and local landowners to increase and redirect summer and/or fall outflows from the Colusa Basin Drain into the Yolo Bypass perennial Toe Drain. Summer-fall flow pulses from the NDFA are managed with the goal of distributing food resources downstream to enhance the quality and quantity of food for Delta Smelt and other species in the downstream regions of the Cache Slough Complex and lower Sacramento River. This management action was initiated after monitoring studies in 2011 and 2012 observed fall phytoplankton blooms in the lower Sacramento River after higher-than-normal fall agricultural return flows passed through the Yolo Bypass (FLaSH; Brown et al. 2014; Frantzich et al. 2018). Due to the potential benefits of summer-fall flow pulses through Yolo Bypass to the Delta food web, the Delta Smelt Resiliency Strategy included managed flow pulses as a core strategy to benefit Delta Smelt (CNRA 2016). In 2019, the NDFA was included as one of several adaptive management strategies of the Delta Smelt Summer-Fall Habitat Action, a new regulatory requirement in both the 2019 Fish and Wildlife Service Biological Opinion and 2020 Department of Fish and Wildlife Incidental Take Permit for the operation of the State Water Project and Central Valley Project. LIS is the only long-term monitoring station in the network of NDFS water quality stations to monitor trends and water quality effects in the Yolo Bypass due to seasonal flow pulses.  

# Primary Habitat Type 

The habitat type is riparian channel and floodplain drainage.  

# Physical Region and Bathymetry

LIS is 7 miles south of West Sacramento in the Toe Drain of the Yolo Bypass. The Toe Drain parallels the eastern edge of the Yolo Bypass floodplain and operates as a drain for water travelling from the Bypass to the Delta. The Sacramento Deepwater Ship Channel is across the east levee from the Toe Drain.
```{r import coordinate data, message=FALSE, warning=FALSE, echo = FALSE}
# Table 1. Station Location
table1 <- read_csv(
   file = "LIS_table1.csv",  #######File name----
   col_names = TRUE) 
gt(table1) %>%
  tab_header(title = md("Table 1. Station Location - (WGS84)")) %>%
  opt_stylize(style = 5, 
              add_row_striping = TRUE) %>%
  cols_align(align = "center",
             columns = 2:5) %>%
  tab_options(heading.align = "left")
```
<br>

![LIS Station Photo](StationPhoto.png))

The LIS YSI sonde is at a fixed depth inside a 6-inch PVC pipe which is attached to a stationary dock on eastern bank. The LIS station is about 200 meters downstream of the Lisbon Weir and is tidally influenced. The Lisbon Weir acts as a tidal barrier, allowing water to pass upstream during flood tides with a series of one-way flap-gates on the west side. Additionally, water overtops the entire length of the rock weir (at peak high tide) and traps the water on an ebb tide upstream of the barrier for agricultural users. The weir was designed to slow the movement of water allowing a pool of water to form upstream of the weir and maintain higher water level during low tide for agricultural pumping and irrigation for seasonal floodplain crops.


Bathymetry data taken near LIS in November 2019 display variable channel depth with higher elevations (shallower waters) closer to the Lisbon Weir and lower elevations (deeper water) closer to the LIS station. The location of LIS is generally in an area of changing water depth due to bathymetry changes and may be reflected in water quality readings as well as tidal flux. Comparatively, the channel’s banks are generally shallower with increasing depth towards center channel.

![LIS Cahnnel Elevation Photo](ChannelElevation.png))

# Station Equipment

NCRO WQES uses a Yellow Springs Instruments (YSI) multiparameter sonde for the continuous data collection. The NCRO Flow and Special Studies Section monitors continuous flow and maintains the telemetry equipment for DWR’s reporting to the California Data Exchange Center (CDEC). Discrete water quality samples are collected at a 1-meter depth using a Van Dorn water sampler.
```{r import equipment data, message=FALSE, warning=FALSE, echo = FALSE}
# Table 2. Station Equipment
table2 <- read_csv(
   file = "LIS_table2.csv",  #######File name----
   col_names = TRUE) 
gt(table2) %>%
  tab_header(title = md("Table 2. Station Equipment")) %>%
  opt_stylize(style = 5, 
              add_row_striping = TRUE) %>%
  cols_align(align = "center",
             columns = 2:3) %>%
  cols_width(2:3 ~ px(150)) %>%
  tab_options(heading.align = "left")
```
<br>
The LIS YSI sonde is at a fixed depth inside a 6-inch PVC pipe which is attached to a stationary dock on eastern bank. The LIS station is about 200 meters downstream of the Lisbon Weir and is tidally influenced. The Lisbon Weir acts as a tidal barrier, allowing water to pass upstream during flood tides with a series of one-way flap-gates on the west side. Additionally, water overtops the entire length of the rock weir (at peak high tide) and traps the water on an ebb tide upstream of the barrier for agricultural users. The weir was designed to slow the movement of water allowing a pool of water to form upstream of the weir and maintain higher water level during low tide for agricultural pumping and irrigation for seasonal floodplain crops.
<br>

![LIS Station Location Photo](StationLocation.png)

# Constituents and Period of Record {.tabset}
## Continuous Record 
All reviewed and quality controlled continuous water quality data is available for downloading for Yolo Bypass near Lisbon Weir (LIS) on Water Data Library [(WDL)] (https://wdl.water.ca.gov/waterdatalibrary/) by searching under ‘Continuous Data’ using Station Number B9156000. 

```{r import missing continuous data, message=FALSE, warning=FALSE, echo = FALSE}
# Table 3. SAMPLING HISTORY AT GLE FOR CONTINUOUS CONSTITUENTS INCLUDING PERIODS OF MISSING DATA (2013-2022).
table3 <- read_csv(
   file = "LIS_table3.csv",  #######File name----
   col_names = TRUE) 
table3 %>% gt() %>%
  tab_header(title = md("Table 3. Continuous Sampling History (2013-2022) with Consecutive Periods of Missing Data (6+ months)")) %>%
  opt_stylize(style = 5, 
              add_row_striping = TRUE) %>%
  cols_align(align = "center",
             columns = 2:4) %>%
  tab_options(heading.align = "left")
```

## Discrete Record
All reviewed and quality controlled discrete grab sample water quality data is available on WDL at <https://wdl.water.ca.gov>. Search WDL under ‘Water Quality’ using Station Name **Yolo Bypass Toe Drain Below Lisbon Weir** or Station Number B9D82851352.


## Summary Table


```{r summarize continuous data in table form, echo=FALSE, message=FALSE, warning=FALSE}
# continuous table
daily_summary <- df_clean_L %>% 
  group_by(Parameter,Date) %>% 
  summarize(Daily_avg=mean(Value, na.rm = TRUE),
            Daily_max=max(Value, na.rm = TRUE),
            Daily_min=min(Value, na.rm = TRUE),
            Daily_range=sum(Daily_max-Daily_min, na.rm = TRUE))

sum_tbl <- daily_summary %>% drop_na() %>% 
  group_by(Parameter) %>% 
  summarize(n = sum(!is.na(Daily_avg)),
            Mean=mean(Daily_avg, na.rm=TRUE),
            Max=max(Daily_avg, na.rm = TRUE),
            Min=min(Daily_avg, na.rm = TRUE),
            StdDev= sd(Daily_avg, na.rm=TRUE),
            MAD=mad(Daily_avg, na.rm = TRUE),
            AvgRng=mean(Daily_range, na.rm = TRUE))

df_date <- daily_summary %>% drop_na() %>% select(1:3)
date_max <- df_date %>% slice_max(Daily_avg) %>% rename("max_date" = Date,
                                                        "Max" = Daily_avg)
date_min <- df_date %>% slice_min(Daily_avg) %>% rename("min_date" = Date,
                                                        "Min" = Daily_avg)
df_table <- full_join(full_join(sum_tbl,date_max),date_min) %>% 
  relocate(max_date, .after = Max) %>% 
  relocate(min_date, .after = Min) %>%
  #UPDATE STATION CODE IDENTIFICATION------------
  mutate(StationCode = "LIS") %>% 
  relocate(StationCode)

dates <- sum_tbl %>% 
  pivot_longer(2:8, names_to = "Statistic", values_to = "para") %>% 
  pivot_wider(names_from = Parameter, values_from = para)

sum_tbl <- sum_tbl %>% rename("SD" = StdDev, "Avg Rng" = AvgRng)

gt(sum_tbl) %>%
  fmt_number(columns = (3:8),
             rows = c(1,3,4,8),
             decimals = 2) %>%
  fmt_number(columns = (3:8),
             rows = c(2,6,7),
             decimals = 1) %>%
  fmt_number(columns = (3:8),
             rows = c(5),
             decimals = 0) %>%
  #cols_align(align = "center",
  #           columns = 2:8) %>%
  cols_width(Parameter ~ px(275),
             2:8 ~ px(75)) %>%
  opt_stylize(style = 5, 
              add_row_striping = TRUE) %>%
  tab_options(heading.align = "left") %>%
  tab_spanner(columns = 2:8, 
              label = 'LIS (2013-2024)', 
              id = 'spannerA')
```

### Chlorophyll Fluorescence (µg/L)
```{r Chla (µg/L), message=FALSE, warning=FALSE, echo =FALSE}
WY_plots_L$`Chlorophyll Fluorescence (µg/L)`
         #tooltip = c("text"))
```


### Depth (m)
```{r Depth (m), message=FALSE, warning=FALSE, echo =FALSE}
#ggplotly(WY_plots$`Depth (m)`,
 #        tooltip = c("text"))
WY_plots_L$`Depth (m)`
```

### Dissolved Oxygen (mg/L)
```{r DO, message=FALSE, warning=FALSE, echo=FALSE}
#ggplotly(WY_plots$`Dissolved Oxygen (mg/L)`,
 #        tooltip = c("text"))
WY_plots_L$`Dissolved Oxygen (mg/L)`
```

### pH
```{r pH, message=FALSE, warning=FALSE, echo=FALSE}
#ggplotly(WY_plots$`pH units`,
 #        tooltip = c("text"))
WY_plots_L$`pH units`
```

### Specific Conductance (µS/cm)
```{r Spcnd, message=FALSE, warning=FALSE, echo=FALSE}
#ggplotly(WY_plots$`Specific Conductance (µS/cm)`,
 #        tooltip = c("text"))
WY_plots_L$`Specific Conductance (µS/cm)`
```

### Turbidity (FNU)
```{r turbidity, message=FALSE, warning=FALSE, echo=FALSE}
#ggplotly(WY_plots$`Turbidity (FNU)`,
 #        tooltip = c("text"))
WY_plots_L$`Turbidity (FNU)`
```

### Water Temperature (°C)
```{r Water Temperature, message=FALSE, warning=FALSE, echo=FALSE}
#ggplotly(WY_plots$`Water Temperature (°C)`,
 #        tooltip = c("text"))
WY_plots_L$`Water Temperature (°C)`
```

### fDOM (QSU)

```{r fDOM, message=FALSE, warning=FALSE, echo=FALSE}
WY_plots_L$`fDOM (QSU)`
```

## Histogram

```{r visualize histograms, message=FALSE, warning=FALSE, echo=FALSE, fig.width = 8, fig.height = 8}
## Daily average water data calculated from 15-min data
histo_plot2<- df_clean_L %>% group_by(Parameter,Date) %>% summarize(Mean=mean(Value, na.rm=TRUE)) %>% 
  ggplot(., aes(x = Mean, y=after_stat(density))) + 
  facet_wrap(~Parameter, scales = 'free') +
  geom_histogram(binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3))) +
  geom_density(color="green",linewidth=4) +
  theme_bw() +
  labs(x = "Daily Average",
       y = "Density",
       title = "Distribution by Parameter (2013-2022)")
histo_plot2

```

# Summary of Discrete Water Quality {.tabset}
## Timeseries Plots
```{r Table 5, echo=FALSE}
#echo = FALSE parameter prevent printing of the R code and still generated the table
table5 <- dis_sum_table_all
knitr::kable(table5)
```

# References {.tabset}

Brown, L.R., Baxter, R., Castillo, G., Conrad, L., Culberson, S., Erickson, G., Feyrer, F., Fong, S., Gehrts, K.,     Grimaldo, L., Herbold, B., Kirsch, J., Mueller-Solger, A., Slater, S., Souza, K., and Van  Nieuwenhuyse, E., 2014, Synthesis of studies in the fall low-salinity zone of the San Francisco Estuary, September–December 2011: U.S. Geological Survey Scientific Investigations Report 2014–5041, 136 p., http://dx.doi.org/10.3133/sir20145041. 

California Natural Resources Agency. 2016. Delta Smelt Resiliency Strategy.

Frantzich, J., Sommer, T. and Schreier, B., 2018. Physical and biological responses to flow in a tidal freshwater slough complex.*San Francisco Estuary and Watershed Science*, 16(1).

Maguire, A., Frantzich, J., Davis, B., Bedwell, M., and C. Stuart. 2019. North Delta Flow Action Continuous Water Quality Monitoring Report 2019. Prepared by the State of California Department of Water Resources, Division of Regional Assistance, North Central Region Office & Division of Environmental Sciences, Office of Water Quality and Estuarine Ecology.

Twardochleb L., Maguire A., Dixit L., Bedwell M., Orlando J., MacWilliams M., Bever A., and B. Davis. 2021. North Delta Food Subsidies Study: Monitoring Food Web Responses to the North Delta Flow Action, 2019 Report. Department of Water Resources, Division of Environmental Services.


#### Note
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

All reviewed and quality controlled continuous water quality data is available for downloading for Yolo Bypass near Lisbon Weir (LIS) on Water Data Library [(WDL)] (https://wdl.water.ca.gov/waterdatalibrary/) by searching under ‘Continuous Data’ using Station Number B9156000. All reviewed and quality controlled discrete grab sample water quality data is available on WDL by searching in ‘Water Quality’ under ‘Station & County’ using Station Name “Yolo Bypass Toe Drain Below Lisbon Weir” or Station Number B9D82851352.

# **Table 5 SUMMARY STATISTICS FOR ALL DEISCRETE WATER QUALITY SAMPLES COLLECTED FOR LAB ANALYSIS AT LIS**
```{r Table 5, echo=FALSE}
#echo = FALSE parameter prevent printing of the R code and still generated the table
table5 <- dis_sum_table_all
knitr::kable(table5)
```

# **Table 6 SUMMARY STATISTICS FOR ALL CONTINUOUS WATER QUALITY DATA COLLECTED AT LIS**
```{r Table 6, echo=FALSE}
#echo = FALSE parameter prevent printing of the R code and still generated the table
table6 <- data.frame(POR_sum_table)
knitr::kable(table6)
```

# **FIGURE 1 DAILY AVERAGE 15-MINUTE TIMESERIES FOR ALL WATER QUALITY MEASUREMENTS GROUPED BY WET, DRY, AND NORMAL WATER YEARS FOR THE COMPLETE PERIOD OF RECORD (2013-2022, EXCEPT FOR FDOM AND DEPTH WHICH INCLUDE 2019-2022) AT LIS. WATER YEAR HYDROLOGIC CLASSIFICATION INDICES ARE BASED ON DEPARTMENT OF WATER RESOURCES UNIMPAIRED RUNOFF FOR SACRAMENTO AND SAN JOAQUIN VALLEY**
```{r Plot 1, echo=FALSE, warning=FALSE, fig.dim= c(16,10)}
#fig.dim = c(W,H)
WY_plots_L

```

# **FIGURE 2 PERIOD OF RECORD (2013-2022, EXCEPT FOR FDOM AND DEPTH WHICH INCLUDE WATER YEARS 2019-2022) HISTOGRAMS OF DAILY AVERAGES FOR ALL CONTINUOUS WATER QUALITY PARAMETERS MEASURED AT STATION LIS**

```{r Plot 2, echo=FALSE, warning=FALSE, fig.dim= c(16,10)}
#fig.dim = c(W,H)
histo_plot

```

This code was generated using base-R (@R-base) and the Rmarkdown (@Rmarkdown) and ggplot2 (@ggplot2) packages.

# **REFERENCES**
